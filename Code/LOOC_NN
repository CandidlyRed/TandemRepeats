{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"az9d7jzF9vLA"},"outputs":[],"source":["from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XlZFWwbzJZgc"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, TensorDataset, DataLoader\n","\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import roc_auc_score\n","from sklearn.model_selection import train_test_split\n","\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ga4SG5-1ZTTM"},"outputs":[],"source":["def model_eval(model, data_loader, return_preds = False):\n","  model.eval()\n","  y_preds = []\n","  y_true = []\n","  with torch.no_grad():\n","    for inputs, labels in data_loader:\n","      inputs, labels = inputs.to(device), labels.to(device)\n","      outputs = model(inputs)\n","      y_preds.append(outputs)\n","      y_true.append(labels)\n","\n","  y_preds = torch.cat(y_preds).cpu().detach().numpy()\n","  y_true = torch.cat(y_true).cpu().detach().numpy()\n","\n","  if return_preds:\n","    return {'y_true': y_true, 'y_preds': y_preds}\n","  else:\n","    return roc_auc_score(y_true, y_preds)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vZiX0FfXK-V2"},"outputs":[],"source":["################################\n","#### Clean and Process Data ####\n","################################\n","\n","data = 'TRs_annotated_cleaned.csv'\n","df_full = pd.read_csv(data)\n","\n","col_names = df_full.columns\n","categorical = [var for var in df_full.columns if df_full[var].dtype=='O']\n","numerical = [var for var in df_full.columns if df_full[var].dtype!='O']\n","\n","ids = df_full.id\n","\n","df = df_full.drop(['id', 'location', 'region', 'tissue_simple'], axis=1)\n","\n","one_hot_gene_type = pd.get_dummies(df.gene_type, prefix=\"gene_type\", drop_first=True, dtype=int)\n","new_df = pd.concat([df[numerical], one_hot_gene_type], axis=1)\n","new_df.drop(['gene_type_intergenic'], axis=1, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":96,"status":"ok","timestamp":1713683466666,"user":{"displayName":"Tim Gruenloh","userId":"14090738425308861435"},"user_tz":300},"id":"wdHWRlCW1m8L","outputId":"1a4ce42e-4edc-4243-be11-64fa851383df"},"outputs":[{"output_type":"stream","name":"stdout","text":["Size of Training Set: (35887, 56) Shape of Training Labels: (35887,)\n","Size of Testing Set: (1155, 56) Shape of Testing Labels: (1155,)\n"]}],"source":["test_chr = \"chr13_\" # chr1, chr2, chr13\n","\n","test_indices = np.array([index for index, string in enumerate(ids) if test_chr in string])\n","test_ids = df_full.iloc[new_df.index.isin(test_indices)].id\n","\n","X_train = new_df.iloc[~new_df.index.isin(test_indices)]\n","X_test = new_df.iloc[new_df.index.isin(test_indices)]\n","\n","y_train = new_df['label'].iloc[~new_df.index.isin(test_indices)]\n","y_test= new_df['label'].iloc[new_df.index.isin(test_indices)]\n","\n","X_train = X_train.drop('label', axis=1)\n","X_test= X_test.drop('label', axis=1)\n","\n","print('Size of Training Set:', X_train.shape, 'Shape of Training Labels:', y_train.shape)\n","print('Size of Testing Set:', X_test.shape, 'Shape of Testing Labels:', y_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CjcUuCCG1lJZ"},"outputs":[],"source":["# List of column names\n","all_columns = X_train.columns\n","\n","# List to store column names where all values are 0 or 1\n","binary_columns = []\n","\n","# Iterate over each column\n","for column in all_columns:\n","    unique_values = X_train[column].unique()\n","    # Check if unique values contain only 0 and 1\n","    if set(unique_values) == {0, 1}:\n","        binary_columns.append(column)\n","\n","numeric_columns = [elem for elem in all_columns if elem not in binary_columns]\n","\n","# Create a ColumnTransformer to apply different transformations to numeric and binary columns\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('numeric', MinMaxScaler(), numeric_columns),\n","        ('binary', 'passthrough', binary_columns)\n","    ])\n","\n","# Define the pipeline with the preprocessing steps\n","pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n","\n","# Fit and transform the training data\n","X_train_processed = pipeline.fit_transform(X_train)\n","\n","# Transform the test data using the fitted pipeline\n","X_test_processed = pipeline.transform(X_test)\n","\n","# Convert the processed data back to DataFrame (optional)\n","X_train_processed = pd.DataFrame(X_train_processed, columns=numeric_columns + binary_columns)\n","X_test_processed = pd.DataFrame(X_test_processed, columns=numeric_columns + binary_columns)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"03B_SNVsM16O"},"outputs":[],"source":["# Convert data to PyTorch tensors\n","X_train_tensor = torch.tensor(X_train_processed.values, dtype=torch.float32)\n","y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n","X_test_tensor = torch.tensor(X_test_processed.values, dtype=torch.float32)\n","y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n","\n","# Create a PyTorch dataset and dataloaders\n","train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n","test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n","\n","batch_size = 64\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":582,"status":"ok","timestamp":1713683473381,"user":{"displayName":"Tim Gruenloh","userId":"14090738425308861435"},"user_tz":300},"id":"-6if-vBubrDW","outputId":"4614a4d6-1430-401e-cc32-7cf80402c44e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Outcome rate in Training: 0.152\n","Outcome rate in Testing: 0.148\n"]}],"source":["# Find outcome rates\n","ys = []\n","for inputs, labels in train_loader:\n","  ys.append(labels)\n","\n","ys = torch.cat(ys)\n","print('Outcome rate in Training:', torch.mean(ys).detach().numpy().round(3))\n","\n","ys = []\n","for inputs, labels in test_loader:\n","  ys.append(labels)\n","\n","ys = torch.cat(ys)\n","print('Outcome rate in Testing:', torch.mean(ys).detach().numpy().round(3))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ye4cIeCFN_g1"},"outputs":[],"source":["class MLP(nn.Module):\n","    def __init__(self, dropout):\n","        super(MLP, self).__init__()\n","\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        self.fc1 = nn.LazyLinear(500, bias=False)\n","        self.bn1 = nn.BatchNorm1d(500)\n","\n","        self.fc2 = nn.Linear(500, 1000, bias=False)\n","        self.bn2 = nn.BatchNorm1d(1000)\n","\n","        self.fc3 = nn.Linear(1000, 500, bias=False)\n","        self.bn3 = nn.BatchNorm1d(500)\n","\n","        self.fc4 = nn.Linear(500, 1)\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = self.bn1(x)\n","        x = self.dropout(x)\n","\n","        x = F.relu(self.fc2(x))\n","        x = self.bn2(x)\n","        x = self.dropout(x)\n","\n","        x = F.relu(self.fc3(x))\n","        x = self.bn3(x)\n","        x = self.dropout(x)\n","\n","        x = F.sigmoid(self.fc4(x))\n","        return x.squeeze(1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":115,"status":"ok","timestamp":1713683478914,"user":{"displayName":"Tim Gruenloh","userId":"14090738425308861435"},"user_tz":300},"id":"EPgTSSbwODP7","outputId":"b2e476b3-e28c-456d-8f20-56c17149a35b"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n","  warnings.warn('Lazy modules are a new feature under heavy development '\n"]},{"output_type":"execute_result","data":{"text/plain":["MLP(\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (fc1): LazyLinear(in_features=0, out_features=500, bias=False)\n","  (bn1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (fc2): Linear(in_features=500, out_features=1000, bias=False)\n","  (bn2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (fc3): Linear(in_features=1000, out_features=500, bias=False)\n","  (bn3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (fc4): Linear(in_features=500, out_features=1, bias=True)\n",")"]},"metadata":{},"execution_count":80}],"source":["torch.manual_seed(1)\n","model = MLP(0.5)\n","model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XjA2BL9xsPZv"},"outputs":[],"source":["epoch_val_roc = []\n","epoch_train_roc = []\n","best_auc = 0\n","counter = 0\n","EARLY_STOP = np.inf"]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"ZcSy3zpVC0GB"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aq8qMEamQKOX","outputId":"09fdcc94-b77b-4988-8820-6ab4985b3185","executionInfo":{"status":"ok","timestamp":1713686010374,"user_tz":300,"elapsed":2525282,"user":{"displayName":"Tim Gruenloh","userId":"14090738425308861435"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1000/1000 [42:05<00:00,  2.53s/it]\n"]}],"source":["# Define loss function and optimizer\n","### OOPS! Just realized nn.CrossEntropyLoss() expects raw logits not the predicted probabilities will rerun later to see if results change\n","criterion = nn.BCELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","model.to(device)\n","\n","# Train the model\n","num_epochs = 1000\n","for epoch in tqdm(range(num_epochs)):\n","    model.train()\n","    running_loss = 0.0\n","    for inputs, labels in train_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item() * inputs.size(0)\n","    epoch_loss = running_loss / len(train_loader.dataset)\n","\n","    train_auc = model_eval(model, train_loader)\n","\n","    epoch_train_roc.append(train_auc)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6iDhANjJ_3F0"},"outputs":[],"source":["torch.save(model.state_dict(), '/content/drive/My Drive/BMI 776 Final Project/Results/Models/Neural Network/LOOC/model_chr13.pth')"]},{"cell_type":"code","source":["outputs = model_eval(model, test_loader, return_preds=True)"],"metadata":{"id":"je-9AU4EP9eb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pd.DataFrame(outputs, index=test_ids).sort_values('y_preds', ascending=False).to_csv('/content/drive/My Drive/BMI 776 Final Project/Results/Models/Neural Network/LOOC/chr13_scores.csv')"],"metadata":{"id":"6b0xyNyVQETr"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}